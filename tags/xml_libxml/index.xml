<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xml_libxml on Perl programming news, code and culture</title>
    <link>https://dnmfarrell.github.io/tags/xml_libxml/</link>
    <description>Recent content in Xml_libxml on Perl programming news, code and culture</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Jul 2014 12:33:45 +0000</lastBuildDate>
    <atom:link href="https://dnmfarrell.github.io/tags/xml_libxml/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>HTML pro-parsing tips</title>
      <link>https://dnmfarrell.github.io/article/101/2014/7/10/HTML-pro-parsing-tips/</link>
      <pubDate>Thu, 10 Jul 2014 12:33:45 +0000</pubDate>
      
      <guid>https://dnmfarrell.github.io/article/101/2014/7/10/HTML-pro-parsing-tips/</guid>
      <description>

&lt;p&gt;&lt;em&gt;Perl has some fantastic modules for parsing HTML and one of the best is XML::LibXML. It&amp;rsquo;s an interface to the libxml2 C library; super fast but also super-picky. I&amp;rsquo;ve often found XML::LibXML croaking on relatively simple - but incorrectly formed HTML. If you find this, do not give up! This article shares 3 simple techniques for overcoming malformed HTML when parsing with XML::LibXML.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;tip-1-turn-on-recovery-mode:9d73a78b2b77c7daf47ac5782dcbfdfb&#34;&gt;Tip 1: turn on recovery mode&lt;/h3&gt;

&lt;p&gt;If XML::LibXML is croaking on a later part of the HTML, try turning on recovery mode, which will return all of the correctly parsed HTML up until XML::LibXML encountered the error.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-prettyprint&#34;&gt;use XML::LibXML;

my $xml = XML::LibXML-&amp;gt;new( recover =&amp;gt; 1 );
my $dom = $xml-&amp;gt;load_html( string =&amp;gt; $html );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With recovery mode set to 1, the parser will still warn about parsing errors. To suppress the warnings, set recover to 2.&lt;/p&gt;

&lt;h3 id=&#34;tip-2-sanitize-the-input-first-with-html-scrubber:9d73a78b2b77c7daf47ac5782dcbfdfb&#34;&gt;Tip 2: sanitize the input first with HTML::Scrubber&lt;/h3&gt;

&lt;p&gt;Sometimes recovery mode alone is not enough - XML::LibXML will croak at the first whiff of HTML if there are two doctype declarations for example. In these situations, consider sanitizing the HTML with &lt;a href=&#34;https://metacpan.org/pod/HTML::Scrubber&#34;&gt;HTML::Scrubber&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;HTML::Scrubber provides both whitelist and blacklist functions to include or exclude HTML tags and attributes. It&amp;rsquo;s a powerful combination which allows you to create a custom filter to scrub the HTML that you want to parse.&lt;/p&gt;

&lt;p&gt;By default HTML::Scrubber removes all tags, but in the case of a duplicate doctype declaration, you just need that one tag removed. Let&amp;rsquo;s remove all div tags too for good measure:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-prettyprint&#34;&gt;use HTML::Scrubber;

my $scrubber = HTML::Scrubber-&amp;gt;new( deny =&amp;gt; [ &#39;doctype&#39;, &#39;div&#39; ],
                                    allow=&amp;gt; &#39;*&#39; );
my $scrubbed_html = $scrubber-&amp;gt;scrub($html);
my $dom = XML::LibXML-&amp;gt;load_html( string =&amp;gt; $scrubbed_html );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &amp;ldquo;deny&amp;rdquo; rule sets the scrubber blacklist (what to exclude) and the &amp;ldquo;allow&amp;rdquo; rule specifies the whitelist (what to include). Here we passed an asterisk (&amp;rdquo;*&amp;rdquo;) to allow, which means allow everything, but because we&amp;rsquo;re denying div and doctype tags, they&amp;rsquo;ll be removed.&lt;/p&gt;

&lt;h3 id=&#34;tip-3-extract-a-subset-of-data-with-a-regex-capture:9d73a78b2b77c7daf47ac5782dcbfdfb&#34;&gt;Tip 3: extract a subset of data with a regex capture&lt;/h3&gt;

&lt;p&gt;If the subset HTML you want to parse has a unique identifier (such as an id attribute), consider using a regex capture to extract it from the HTML document. You can then scrub or immediately parse this subset with XML::LibXML.&lt;/p&gt;

&lt;p&gt;For example recently I had to extract an HTML table from a badly-formed web page. Fortunately the table had an id attribute, which made extracting it with a regex a piece-of-cake:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-prettyprint&#34;&gt;if ( $html =~ /(&amp;lt;table id=&amp;quot;t2&amp;quot;&amp;gt;.*?&amp;lt;\/table&amp;gt;)/s ) {
    my $dom = XML::LibXML-&amp;gt;load_html( string =&amp;gt; $1 );
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note the use of the &amp;ldquo;s&amp;rdquo; modifier in the regex to match multiline. Many HTML pages contain newlines and you don&amp;rsquo;t want your match fail because of that.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:9d73a78b2b77c7daf47ac5782dcbfdfb&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Hopefully these tips will make parsing HTML with XML::LibXML easier. My GitHub account has a web scraper &lt;a href=&#34;https://gist.github.com/sillymoose/998b9199007589199dce#file-get_swift_code-pl-L42&#34;&gt;script&lt;/a&gt; that uses some of these tips. If you&amp;rsquo;re looking for an entirely different approach to parsing HTML, check out &lt;a href=&#34;https://metacpan.org/pod/XML::Rabbit&#34;&gt;XML::Rabbit&lt;/a&gt; and &lt;a href=&#34;https://metacpan.org/pod/HTML::TreeBuilder&#34;&gt;HTML::TreeBuilder&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Enjoyed this article? Help us out and &lt;a href=&#34;https://twitter.com/intent/tweet?original_referer=http%3A%2F%2Fperltricks.com%2Farticle%2F101%2F2014%2F7%2F10%2FHTML-pro-parsing-tips&amp;amp;text=HTML+pro-parsing+tips&amp;amp;tw_p=tweetbutton&amp;amp;url=http%3A%2F%2Fperltricks.com%2Farticle%2F101%2F2014%2F7%2F10%2FHTML-pro-parsing-tips&amp;amp;via=perltricks&#34;&gt;tweet&lt;/a&gt; about it!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

