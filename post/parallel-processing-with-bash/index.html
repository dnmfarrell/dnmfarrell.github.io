<!DOCTYPE html>
<html>
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Parallel Processing with Bash</title>
  <meta name="description" content="How named pipes enable a general-purpose forking worker model" />
  <link rel="stylesheet" href="/assets/css/style.css" type="text/css">
  <meta property="og:url" content="https://blog.dnmfarrell.com/post/parallel-processing-with-bash/" />
  <meta property="og:title" content="Parallel Processing with Bash" />
  <meta property="og:description" content="How named pipes enable a general-purpose forking worker model">
  <meta property="og:site_name" content="blog.dnmfarrell.com" />
  <meta property="og:type" content="article" />
  <meta property="og:article:published_time" content="2023-02-12T28:37:23Z" />
  <meta property="og:article:tag" content="fifo" />
  <meta property="og:article:tag" content="trap" />
  <meta property="og:article:tag" content="pipe" />
  <meta property="og:article:tag" content="fork" />
  <meta property="og:article:tag" content="shell" />
  <meta property="og:article:tag" content="concurrency" />
</head>

  <body>
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZZXLDS5VZ0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-ZZXLDS5VZ0');
</script>
<a href="/">
  <h1>Code</h1>
</a>

    <main>
      

<div class="post-title">
  <a href=https://blog.dnmfarrell.com/post/parallel-processing-with-bash/><h2>Parallel Processing with Bash</h2></a>
  <p class="description">How named pipes enable a general-purpose forking worker model</p>
  <p><em class="date">February 12, 2023</em></p>
</div>

<p>Last week at work I had to whip up a script to process several thousand ids for product analysis on a new feature we&rsquo;re launching. The processing included making HTTP requests to a service, and I was on a deadline, so the script had to be concurrent. Here&rsquo;s what I came up with:</p>
<pre><code>#!/bin/bash
startline=2
setsize=1200
for i in {1..5};do
  tail -n+$startline ids.tsv \
    | cut -f4 \
    | head -n $setsize \
    | ./get-service.bash \
    &gt; output/$startline.tsv&amp;
  startline=$((startline+setsize))
done
wait
</code></pre>
<p>It combines <code>tail</code> and <code>head</code> to split the source file into five streams that are piped to the get-service script, which reads from STDIN and makes an HTTP GET request for each line of input.</p>
<p>It worked, but a couple of things nagged at me. The first is that <code>open</code> and <code>seek</code> is called on the input file five times, but each line of input is only used once. What if the input file was <em>really</em> large, or an infinite stream? The second is that the script is too-specific â€” I wrote one just like this for another urgent data-processing request last month! So I wanted to generalize the pattern of distributing an input stream among a pool of workers.</p>
<p>I call the program <a href="https://github.com/dnmfarrell/forklift">forklift</a>:</p>
<pre><code>#!/bin/sh
set -eu
num_workers=1
num_fifos=0
next_fifo=1
fifo_prefix=&quot;${TMPDIR-/tmp}/forklift-$$&quot;

cleanup() {
  rm -f &quot;$fifo_prefix&quot;*
  wait
}
trap cleanup ABRT EXIT INT TERM

# process args
while getopts &quot;w:&quot; opt; do
  case &quot;$opt&quot; in
  'w') num_workers=&quot;$OPTARG&quot; ;;
  *)
    printf &quot;Usage:\n\tforklift [-w #] command\n&quot;
    exit 1
    ;;
  esac
done
shift $((OPTIND - 1))
if [ $# -ne 1 ]; then
  printf &quot;Must provide 1 command. Usage:\n\tforklift [-w #] command\n&quot;
  exit 1
fi

# fork child lock
export lock=&quot;$fifo_prefix-lock&quot;
touch &quot;$lock&quot;
{
  while [ -f &quot;$lock&quot; ]; do
    sleep 1
  done
} &amp;
lockpid=$!

# distribute input
while read -r line; do
  if [ &quot;$next_fifo&quot; -gt &quot;$num_fifos&quot; ]; then
    num_fifos=$((num_fifos + 1))
    mkfifo &quot;$fifo_prefix-$num_fifos&quot;
    tail --pid $lockpid -f &quot;$fifo_prefix-$num_fifos&quot; | $1 &amp;
  fi
  echo &quot;$line&quot; &gt;&quot;$fifo_prefix-$next_fifo&quot;
  if [ &quot;$next_fifo&quot; -eq &quot;$num_workers&quot; ]; then
    next_fifo=1
  else
    next_fifo=$((next_fifo + 1))
  fi
done
</code></pre>
<p>It starts by declaring a bunch of globals and a clean up function, which is called when the program receives a signal or is exiting normally.</p>
<p>The next stanza processes arguments; it accepts a <code>-w</code> option for the number of workers to use, and a command to run. The odd-looking command <code>shift $((OPTIND-1))</code> removes processed-options from the argument stack so all that&rsquo;s left (should be) the command to run.</p>
<p>Next it creates a lockfile and forks a child worker that loops until the lockfile is removed. This indirection is needed so that the worker pool subprocesses can be created as direct children of the forklift process so it will <code>wait</code> for them to exit <em>and</em> the lockfile worker pid can be passed to <code>tail</code> so that the tailed workers shutdown when the lockfile worker exits.</p>
<p>The final loop round-robin distributes input between the workers. It first checks if the next worker exists or not, and if not, it creates a named pipe (fifo) and forks a worker which tails the fifo into the command argument. This check is necessary to avoid the edge case where more workers are requested than lines of input received, and they end up blocking on read forever. Also unlike shell <code>read</code>, <code>tail -f</code> is really persistent in its attempts to read from the fifo, which avoids inconsistent behavior passing input to the command.</p>
<p>One downside of the persistence of <code>tail -f</code> is it won&rsquo;t exit when the named pipe is removed. That&rsquo;s why the <code>--pid</code> argument is used to make <code>tail</code> exit when the lockfile worker exits. And since <code>--pid</code> is not in the <a href="https://pubs.opengroup.org/onlinepubs/007904875/utilities/tail.html">POSIX spec</a>, <code>forklift</code> is not POSIX compliant. This means it won&rsquo;t work on macOS (I think). If I could figure out a way to get the PID of the tail process (not the piped command), perhaps this arrangement could be dropped in favor of sending a sigterm to tail.</p>
<p>Named pipes are like regular pipes except they can be passed around by filepath. Deleting the fifo &ldquo;closes&rdquo; the pipe, which makes them convenient for distributing input among a worker pool.</p>
<p>Now, using bash as a parallel stream processor is never going to break any speed records. Pipes and fifos are generally fast because they avoid filesystem IO, but are not the fastest option for IPC:</p>
<blockquote>
<p>Data has to be copied from user space in one process to a kernel buffer and then back to user space which is expensive (message queues and sockets have the same disadvantage).</p>
<p class="source">&mdash;&nbsp;Rochkind, <em>Advanced Unix Programming 2nd edition, chapter 7</em></p>

</blockquote>
<p>However, assuming the command is doing something slow like making a network request (i.e. worth parallelizing), this limitation won&rsquo;t matter much</p>
<p>Once the parent has distributed all of its input, it &ldquo;exits&rdquo;, triggering the removal of the fifos and lockfile and waits for the workers to exit.</p>


<p>


<em>Tags: 



  
  
  

  <a href=https://blog.dnmfarrell.com/tags/fifo/>fifo</a>



  
  
  

  <a href=https://blog.dnmfarrell.com/tags/trap/>trap</a>



  
  
  

  <a href=https://blog.dnmfarrell.com/tags/pipe/>pipe</a>



  
  
  

  <a href=https://blog.dnmfarrell.com/tags/fork/>fork</a>



  
  
  

  <a href=https://blog.dnmfarrell.com/tags/shell/>shell</a>



  
  
  

  <a href=https://blog.dnmfarrell.com/tags/concurrency/>concurrency</a>



</em>



</p>


    </main>
    <footer>
</footer>

  </body>
</html>
